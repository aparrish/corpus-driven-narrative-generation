{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A few simple corpus-driven approaches to narrative analysis and generation\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "This notebook is a fast introduction to a few techniques for working with narrative corpora. By \"narrative corpora,\" I mean pre-existing bodies of text that mostly contain the texts of narratives. In particular, we're going to use Mark Riedl's [WikiPlots corpus](https://github.com/markriedl/WikiPlots), which has the titles and plot summaries of more than one hundred thousand movies, books, television shows and other media from Wikipedia.\n",
    "\n",
    "The notebook takes you through using [spaCy](http://spacy.io) to extract words, noun chunks, parts of speech and entities from the text and then sew them back together with [Tracery](http://tracery.io). It then shows how to use [Markovify](https://github.com/jsvine/markovify) to create new narratives from existing narrative text, along with a quick example of recurrent neural network text generation with [textgenrnn](https://github.com/minimaxir/textgenrnn).\n",
    "\n",
    "The code is written in Python, but you don't really need to know Python in order to use the notebook. Everything's pre-written for you, so you can just execute the cells, making small changes to the code as needed. Even if the notebook itself doesn't end up being useful to you, hopefully it spurs a few ideas that you can take with you into your practice as a storyteller and/or programmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the corpus\n",
    "\n",
    "The first step is to get the narrative corpus into the program. Because WikiPlots is so big, we're actually going to be working with a smaller subset: only the plot summaries for romantic comedy movies. The subcorpus was made using [this notebook on creating a subcorpus of WikiPlots](creating-a-wikiplots-subcorpus.ipynb), which you can consult if you want to make your own with a different subset of WikiPlots.\n",
    "\n",
    "The corpus we're working with takes the form of a TSV file (\"tab separated values\"), with each line containing the title of the movie, a number indicating where in the plot summary the sentence for this line occurs, the total number of sentences in the summary, and the actual text of the sentence. The following cell loads the data into a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for line in open(\"romcom_plot_sentences.tsv\"):\n",
    "    line = line.strip()\n",
    "    items = line.split(\"\\t\")\n",
    "    sentences.append(\n",
    "        {'title': items[0],\n",
    "         'index': int(items[1]),\n",
    "         'total': int(items[2]),\n",
    "         'text': items[3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it worked, we'll print out a random sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 15,\n",
       " 'text': 'Throughout the first season, it is hinted that Jimmy expected the arrangement to be temporary and he sometimes wonders aloud when Edgar will move out.',\n",
       " 'title': \"You're the Worst\",\n",
       " 'total': 17}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what's happening in the text of the plots, we can do a bit of Natural Language Processing. I cover just the bare essentials in this notebook. [Here's a more in-depth tutorial that I wrote](https://github.com/aparrish/rwet/blob/master/nlp-concepts-with-spacy.ipynb).\n",
    "\n",
    "Most natural language processing is done with the aid of third-party libraries. We're going to use one called spaCy. To use spaCy, you first need to install it (i.e., download the code and put it in a place where Python can find it) and download the language model. (The language model contains statistical information about a particular language that makes it possible for spaCy to do things like parse sentences into their constituent parts.)\n",
    "\n",
    "If you're using this notebook in Binder, then spaCy has already been installed for you! Otherwise, to install spaCy, [follow the instructions here](https://spacy.io/usage/). If you're using Anaconda, you'll need to open a Terminal window (or the equivalent on your operating system) and type\n",
    "\n",
    "    conda install -c conda-forge spacy\n",
    "\n",
    "This line installs the library. You'll also need to download a language model. For that, type:\n",
    "\n",
    "    python -m spacy download en_core_web_sm\n",
    "\n",
    "(Replace en with the language code for your desired language, if there's a model available for it.) The language model contains the statistical information necessary to parse text into sentences and sentences into parts of speech. Note that this download is several hundred megabytes, so it might take a while!\n",
    "\n",
    "Once you've installed the library and downloaded the model, you should be able to load the model in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This could also take a while–the model is potentially very large and your computer needs to load it from your hard drive and into memory. When you see a `[*]` next to a cell, that means that your computer is still working on executing the code in the cell.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, the spaCy library gives us access to a number of interesting units of text:\n",
    "\n",
    "* All of the sentences (`doc.sents`)\n",
    "* All of the words (`doc`)\n",
    "* All of the \"named entities,\" like names of places, people, #brands, etc. (`doc.ents`)\n",
    "* All of the \"noun chunks,\" i.e., nouns in the text plus surrounding matter like adjectives and articles\n",
    "\n",
    "The cell below, we extract these into variables so we can play around with them a little bit. (Parsing sentences is hungry work and the following cell will take a while to execute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22593\n",
      "1000 22593\n",
      "2000 22593\n",
      "3000 22593\n",
      "4000 22593\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "noun_chunks = []\n",
    "entities = []\n",
    "# only use 5000 sentences sampled at random by default; comment out this `for...`\n",
    "# uncomment the `for...` beneath to use every sentence in the corpus.\n",
    "for i, sent in enumerate(random.sample(sentences, 5000)):\n",
    "#for i, sent in enumerate(sentences):\n",
    "    if i % 1000 == 0:\n",
    "        print(i, len(sentences))\n",
    "    doc = nlp(sent['text'])\n",
    "    words.extend([w for w in list(doc) if w.is_alpha])\n",
    "    noun_chunks.extend(list(doc.noun_chunks))\n",
    "    entities.extend(list(doc.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it worked, print out ten random words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "Hampshire\n",
      "intercourse\n",
      "in\n",
      "his\n",
      "Judge\n",
      "John\n",
      "Toninho\n",
      "to\n",
      "Using\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(words, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten random noun chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him\n",
      "a nightmare\n",
      "store manager\n",
      "her own daughter\n",
      "harp music\n",
      "her\n",
      "he\n",
      "Kate\n",
      "ndash\n",
      "Sam Beacham\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(noun_chunks, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten random entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom\n",
      "Ted\n",
      "Ramona\n",
      "Scott\n",
      "Chester Hooton\n",
      "Andie\n",
      "Distraught\n",
      "Harold\n",
      "Rodeo Drive\n",
      "Mabel\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(entities, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammatical roles\n",
    "\n",
    "The parser included with spaCy can also give us information about the grammatical roles in the sentence. For example, the `.root.dep_` attribute of a noun chunk tells us whether that noun chunk is the subject of the sentence (\"nsubj\") or a direct object (\"dobj\") of the sentence. (See the \"Universal Dependency Labels\" of spaCy's [annotation specs](https://spacy.io/api/annotation) for more possible roles.) Using this information, we can make a list of sentence subjects and sentence objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [chunk for chunk in noun_chunks if chunk.root.dep_ == 'nsubj']\n",
    "objects = [chunk for chunk in noun_chunks if chunk.root.dep_ == 'dobj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[he, he, Kasim, you, Chris, she, the best man, Max, Danielle, it]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(subjects, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Kevin,\n",
       " genital herpes,\n",
       " the blame,\n",
       " a Christmas present,\n",
       " David,\n",
       " Murray,\n",
       " her,\n",
       " manners,\n",
       " what,\n",
       " the business]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(objects, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of speech\n",
    "\n",
    "The spaCy parser allows us to check what part of speech a word belongs to. In the cell below, we create four different lists—`nouns`, `verbs`, `adjs` and `advs`—that contain only words of the specified parts of speech. Using the `.tag_` attribute, we can easily get only particular forms of verbs; in this case, I'm just getting verbs that are in the past tense. ([There's a full list of part of speech tags here](https://spacy.io/docs/usage/pos-tagging#pos-tagging-english).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]\n",
    "past_tense_verbs = [w for w in words if w.tag_ == 'VBD']\n",
    "adjs = [w for w in words if w.pos_ == \"ADJ\"]\n",
    "advs = [w for w in words if w.pos_ == \"ADV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can print out a random sample of any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "relationship\n",
      "insurance\n",
      "daughter\n",
      "adultery\n",
      "who\n",
      "events\n",
      "accident\n",
      "arms\n",
      "security\n",
      "mother\n",
      "activities\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(nouns, 12): # change \"nouns\" to \"verbs\" or \"adjs\" or \"advs\" to sample from those lists!\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity types\n",
    "\n",
    "The parser in spaCy not only identifies \"entities\" but also assigns them to a particular type. [See a full list of entity types here.](https://spacy.io/docs/usage/entity-recognition#entity-types) Using this information, the following cell builds lists of the people, locations, and times mentioned in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [e for e in entities if e.label_ == \"PERSON\"]\n",
    "locations = [e for e in entities if e.label_ == \"LOC\"]\n",
    "times = [e for e in entities if e.label_ == \"TIME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can print out a random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the night\n",
      "night\n",
      "the night\n",
      "the night\n",
      "later that night\n",
      "That night\n",
      "late-night\n",
      "the night\n",
      "morning\n",
      "one-night\n",
      "one-night\n",
      "night\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(times, 12): # change \"times\" to \"people\" or \"locations\" to sample those lists\n",
    "    print(item.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most common\n",
    "\n",
    "We won't go too deep into text analysis in this tutorial, but it's useful to be able to do the most fundamental task in text analysis: finding the things that are most common. The code to do this task looks like the following, which gives us a way to look up how often any word occurs in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter([w.text for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count['Meanwhile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and also tells us which words are most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4430),\n",
       " ('to', 4166),\n",
       " ('and', 3527),\n",
       " ('a', 2749),\n",
       " ('her', 2058),\n",
       " ('is', 1805),\n",
       " ('of', 1541),\n",
       " ('in', 1523),\n",
       " ('his', 1396),\n",
       " ('he', 1294),\n",
       " ('with', 1275),\n",
       " ('that', 1260)]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a counter for any of the other lists we've worked with using the same syntax. Just make up a unique variable name on the left of the `=` sign and put the name of the list you want to count in the brackets to the right (replacing `words`). E.g., to find the most common people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_count = Counter([w.text for w in people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Joe', 81),\n",
       " ('Tom', 63),\n",
       " ('Steve', 59),\n",
       " ('Mary', 56),\n",
       " ('Sam', 55),\n",
       " ('Peter', 52),\n",
       " ('George', 50),\n",
       " ('Chris', 40),\n",
       " ('Jeff', 39),\n",
       " ('Nick', 37),\n",
       " ('Jack', 37),\n",
       " ('Michael', 36)]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common past-tense verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbd_count = Counter([w.text for w in past_tense_verbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 190),\n",
       " ('had', 129),\n",
       " ('did', 38),\n",
       " ('were', 25),\n",
       " ('left', 19),\n",
       " ('got', 18),\n",
       " ('gave', 16),\n",
       " ('wanted', 14),\n",
       " ('married', 13),\n",
       " ('made', 13),\n",
       " ('died', 12),\n",
       " ('met', 12)]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbd_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a file\n",
    "\n",
    "The following cell defines a function for writing data from a `Counter` object to a file. The file is in \"tab-separated values\" format, which you can open using most spreadsheet programs. Execute it before you continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_counter_tsv(filename, counter, limit=1000):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        outfile.write(\"key\\tvalue\\n\")\n",
    "        for item, count in counter.most_common():\n",
    "            outfile.write(item.strip() + \"\\t\" + str(count) + \"\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following cell. You'll end up with a file in the same directory as this notebook called `100_common_words.tsv` that has two columns, one for the words and one for their associated counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_counter_tsv(\"100_common_words.tsv\", word_count, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try opening this file in Excel or Google Docs or Numbers!\n",
    "\n",
    "If you want to write the data from another `Counter` object to a file:\n",
    "\n",
    "* Change the filename to whatever you want (though you should probably keep the `.tsv` extension)\n",
    "* Replace `word_count` with the name of any of the `Counter` objects we've made in this sheet and use it in place of `word_count`\n",
    "* Change the number to the number of rows you want to include in your spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When do things happen in this text?\n",
    "\n",
    "Here's another example. Using the `times` entities, we can make a spreadsheet of how often particular \"times\" (durations, times of day, etc.) are mentioned in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_counter = Counter([e.text.lower().strip() for e in times])\n",
    "save_counter_tsv(\"time_count.tsv\", time_counter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing, but with people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_counter = Counter([e.text.lower() for e in people])\n",
    "save_counter_tsv(\"people_count.tsv\", people_counter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating stories from a corpus and Tracery grammars\n",
    "\n",
    "Once you've isolated entities and parts of speech, you can recombine them in interesting ways. One is to use a Tracery grammar to write sentences that include the isolated parts. Because the parts have been labelled using spaCy, you can be reasonbly sure that they'll fit into particular slots in the sentence. (I used a similar technique for my [Cheap Space Nine](https://twitter.com/cheapspacenine) bot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"subject\": [w.text for w in subjects],\n",
    "    \"object\": [w.text for w in objects],\n",
    "    \"verb\": [w.text for w in past_tense_verbs],\n",
    "    \"adj\": [w.text for w in adjs],\n",
    "    \"people\": [w.text for w in people],\n",
    "    \"loc\": [w.text for w in locations],\n",
    "    \"time\": [w.text for w in times],\n",
    "    \"origin\": \"#scene#\\n\\n[charA:#subject#][charB:#subject#][prop:#object#]#sentences#\",\n",
    "    \"scene\": \"SCENE: #loc#, #time.lowercase#\",\n",
    "    \"sentences\": [\n",
    "        \"#sentence#\\n#sentence#\",\n",
    "        \"#sentence#\\n#sentence#\\n#sentence#\",\n",
    "        \"#sentence#\\n#sentence#\\n#sentence#\\n#sentence#\"\n",
    "    ],\n",
    "    \"sentence\": [\n",
    "        \"#charA.capitalize# #verb# #prop#.\",\n",
    "        \"#charB.capitalize# #verb# #prop#.\",\n",
    "        \"#prop.capitalize# became #adj#.\",\n",
    "        \"#charA.capitalize# and #charB# greeted each other.\",\n",
    "        \"'Did you hear about #object.lowercase#?' said #charA#.\",\n",
    "        \"'#object.capitalize# is #adj#,' said #charB#.\",\n",
    "        \"#charA.capitalize# and #charB# #verb# #object#.\",\n",
    "        \"#charA.capitalize# and #charB# looked at each other.\",\n",
    "        \"#sentence#\\n#sentence#\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENE: Ozarks, the night\n",
      "\n",
      "Dudley was the train.\n",
      "'Did you hear about changes?' said Anabel.\n",
      "\n",
      "SCENE: Europe, every morning\n",
      "\n",
      "What and she looked at each other.\n",
      "'Did you hear about commercial jingles?' said what.\n",
      "\n",
      "SCENE: Vortex, a little of his\n",
      "\n",
      "'Crawl is her,' said The chickens.\n",
      "She and The chickens greeted each other.\n",
      "She and The chickens lost the subject.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain text generation\n",
    "\n",
    "Another way to produce new narratives from existing narrative text is to find statistical patterns in the text itself and then make the computer create new text that follows those statistical patterns. Markov chain text generation has been a pastime of poets and programmers going back [all the way to 1983](https://www.jstor.org/stable/24969024), so it should be no surprise that there are many implementations of the idea in Python that you can download and install. The one we're going to use is [Markovify](https://github.com/jsvine/markovify), a Markov chain text generation library originally developed for BuzzFeed, apparently. Writing [code to implement a Markov chain generator](https://github.com/aparrish/rwet/blob/master/ngrams-and-markov-chains.ipynb) on your own is certainly possible, but Markovify comes with a lot of extra niceties that will make our lives easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install Markovify on your computer, run the cell below. (You can skip this step if you're using this notebook in Binder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/allison/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: unidecode in /Users/allison/anaconda/lib/python3.6/site-packages (from markovify)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then run this cell to make the library available in your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of strings to train the Markov generator. For now, let's just get all of the sentences from any movie in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [item['text'] for item in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell creates a new text generator, using the text in the variable specified to build the Markov model, which is then assigned to the variable `all_text_gen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text_gen = markovify.Text(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then call the `.make_sentence()` method to generate a sentence from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirley Mae's troubles come to an end on the history and artworks of Paris.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.make_short_sentence()` method allows you to specify a maximum length for the generated sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kenneth carries her into the Italian Music Awards.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Markovify tries to generate a sentence that is significantly different from any existing sentence in the input text. As a consequence, sometimes the `.make_sentence()` or `.make_short_sentence()` methods will return `None`, which means that in ten tries it wasn't able to generate such a sentence. You can work around this by increasing the number of times it tries to generate a sufficiently unique sentence using the `tries` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She reminds him of insincerity.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(40, tries=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by disabling the check altogether with `test_output=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their talk is interrupted by Stifler.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(40, test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the order\n",
    "\n",
    "When you create the model, you can specify the order of the model using the `state_size` parameter. It defaults to 2. Let's make two model with different orders and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_1 = markovify.Text(all_text, state_size=1)\n",
    "gen_4 = markovify.Text(all_text, state_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order 1\n",
      "Even though the hope that the professors drive back to doctors.\n",
      "\n",
      "order 4\n",
      "Ken who is the law office receptionist, is smitten with her.\n"
     ]
    }
   ],
   "source": [
    "print(\"order 1\")\n",
    "print(gen_1.make_sentence(test_output=False))\n",
    "print()\n",
    "print(\"order 4\")\n",
    "print(gen_4.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the higher the order, the more the sentences will seem \"coherent\" (i.e., more closely resembling the source text). Lower order models will produce more variation. Deciding on the order is usually a matter of taste and trial-and-error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the level\n",
    "\n",
    "Markovify, by default, works with *words* as the individual unit. It doesn't come out-of-the-box with support for character-level models. The following code defines a new kind of Markovify generator that implements character-level models. Execute it before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SentencesByChar(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the parameters you passed to `markovify.Text` you can also pass to `SentencesByChar`. The `state_size` parameter still controls the order of the model, but now the n-grams are characters, not words.\n",
    "\n",
    "The following cell implements a character-level Markov text generator for the word \"condescendences\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_model = SentencesByChar(\"condescendences\", state_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see the output—it'll be a lot like what we implemented by hand earlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'condencescencencencencescesces'"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_model.make_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can use a character-level model on any text of your choice. So, for example, the following cell creates a character-level order-7 Markov chain text generator from text A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_char = SentencesByChar(all_text, state_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the cell below prints out a random sentence from this generator. (The `.replace()` is to get rid of any newline characters in the output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff realizes that she lost that they do, Lee carrying her himself off from a devastating the Hostess Room of the objects him.\n"
     ]
    }
   ],
   "source": [
    "print(gen_char.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about structure\n",
    "\n",
    "It's one thing to be able to produce one plausible sentence of a plot summary using Markov chains, but another to create a sense of overall structure between sentences, and generating narratives with these kinds of long-term dependencies is still an open problem in computational creativity. The approach I'm going to suggest below relies on the intuition that sentences in a plot summary share characteristics based on their position in the summary. First sentences will generally introduce characters and present an initial situation; last sentences will generally describe how the situation was resolved; and sentences in between will describe developing action.\n",
    "\n",
    "Following this intuition, let's create *three different Markov chains*: one for beginning sentences, one for middle sentences, and one for final sentences. We can use the `index` of each sentence in our corpus to give us this information.\n",
    "\n",
    "First, the beginnings are lines whose index is zero (i.e., they're the first sentence for this plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginnings = [line['text'] for line in sentences if line['index'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucky Fritz was hit by a lightning strike twice.',\n",
       " 'Judy (Swanson) and Nicholas Randall (Olivier) are a newly married couple who agree to a marriage based on \"perfect understanding\".',\n",
       " 'Confirmed bachelor Jud Parker (Larry Parks) likes his life the way it is.',\n",
       " 'Gary Starke (Garcia) is a New York City ticket scalper who, in the old traditional style of scalping \"works the street\", known as \"the walk\", as opposed to the plethora of modern-day ticket brokers who ply the Internet for sales.',\n",
       " 'Renowned surgeon Sir Lancelot Spratt (James Robertson Justice) arranges a cruise for his patient, the famous television star Basil Beauchamp (Simon Dee).']"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(beginnings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And endings are sentences that come last in the plot (i.e., their index is one less than the total number of sentences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "endings = [line['text'] for line in sentences if line['index'] == line['total'] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Regrettably surveying the wreckage of his work, David soon accepts the destruction and chaos, gives in, and hugs and kisses Susan.',\n",
       " 'Upon learning the news, Alfie drives to the crash site and cries over the wreckage.',\n",
       " \"(Zak Orth) attempt to figure out why McKinley (Michael Ian Black) hasn't been with a woman, the reason being that McKinley is in love with Ben (Bradley Cooper), whom he marries in a ceremony in the lake; Victor (Ken Marino) attempts to lose his virginity with the resident loose-girl Abby (Marisa Ryan); and Susie (Amy Poehler) and Ben attempts to produce and choreograph the greatest talent show Camp Firewood has ever seen.\",\n",
       " 'But this simple transaction will bring problems after Uma gets pregnant, and the feelings that no one was waiting for appear, transforming the lives of each of the characters.',\n",
       " 'Mickey and Ellen arrive at the restaurant together and re-tell Liz the story of their relationship.']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(endings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And \"middles\" are anything in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "middles = [line['text'] for line in sentences if 0 < line['index'] < line['total'] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Later, apparently on a spur of the moment, she lends Randy a copy of Walt Whitman’s Leaves of Grass, which Randy starts to devour.',\n",
       " 'Serving with the 3rd Armored \"Spearhead\" Division in West Germany, McLean dreams of running his own nightclub when he leaves the army, but such dreams don\\'t come cheap.',\n",
       " 'When Maisie notices that they are being billed for twice as many parts (the plotters are building a second copy of the prototype), Barbara invites her to a Sunday social at an exclusive club, where she spikes her drink.',\n",
       " \"The friendship is soon to become more, as Brendan appears unexpectedly late one night at Leo's door and sleeps with him; after which they become something of a couple, to the consternation of one man in their men's group, though it encourages another, Terry (Con O'Neill), to explore his sexuality.\",\n",
       " 'The relationship between Melvin and Carol remains complicated until Simon (whom Melvin has allowed to move in with him until he can fully heal from his injuries and get a new apartment) convinces Melvin to declare his love for her.']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(middles, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning_gen = markovify.Text(beginnings)\n",
    "middle_gen = markovify.Text(middles)\n",
    "ending_gen = markovify.Text(endings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can generate tiny narratives by producing a beginning sentence, a middle sentence, and an ending sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The film opens with a soldier and nurse getting out of college and ready to propose to her.\n",
      "Things get so complicated that the film leads to a children's playing area to the Royal Court.\n",
      "Logan, however, decides to marry him.\n"
     ]
    }
   ],
   "source": [
    "print(beginning_gen.make_short_sentence(100))\n",
    "print(middle_gen.make_short_sentence(100))\n",
    "print(ending_gen.make_short_sentence(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The narratives still feel disconnected (and there are often jarring mismatches in pronoun antecedents), but the artifacts produced with this method do feel a bit narrative-like? Maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining models\n",
    "\n",
    "Markovify has a handy feature that allows you to *combine* models, creating a new model that draws on probabilities from both of the source models. You can use this to create hybrid output that mixes the style and content of two (or more!) different source texts. To do this, you need to create the models independently, and then call `.combine()` to combine them.\n",
    "\n",
    "The code below combines models for beginning sentences, middle sentences, and ending sentences into one model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combo = markovify.combine([beginning_gen, middle_gen, ending_gen], [10, 1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bit of code `[10, 1, 10]` controls the \"weights\" of the models, i.e., how much to emphasize the probabilities of any model. You can change this to suit your tastes. (E.g., if you want mostly beginnings with but a bit of middles and a *soupçon* of ends, try `[10, 2, 1]`.)\n",
    "\n",
    "Then you can create sentences using the combined model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff realizes he loves her and the film closes.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_short_sentence(120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network text prediction with `textgenrnn`\n",
    "\n",
    "Like a [Markov chain](ngrams-and-markov-chains.ipynb), a recurrent neural network (RNN) is a way to make predictions about what will come next in a sequence. For our purposes, the sequence in question is a sequence of characters, and the prediction we want to make is *which character will come next*. Both Markov models and recurrent neural networks do this by using statistical properties of text to make a *probability distribution* for what character will come next, given some information about what comes before. The two procedures work very differently internally, and we're not going to go into the gory details about implementation here. (But if you're interested in the gory details, [here's a good place to start](https://karpathy.github.io/2015/05/21/rnn-effectiveness/).) For our purposes, the main *functional* difference between a Markov chain and a recurrent neural network is the *portion* of the sequence used to make the prediction. A Markov model uses a fixed window of history from the sequence, while an RNN (theoretically) uses the *entire history* of the sequence.\n",
    "\n",
    "The primary benefit of an RNN over a Markov model for text generation is that an RNN takes into account *the entire history* of a sequence when generating the next character. This means that, for example, an RNN can theoretically learn how to close quotes and parentheses, which a Markov chain will never be able to reliably do (at least for pairs of quotes and parentheses longer than the n-gram of the Markov chain).\n",
    "\n",
    "The drawback of RNNs is that they are *computationally expensive*, from both a processing and memory perspective. This is (again) a simplification, but internally, RNNs work by \"squishing\" information about the training data down into large matrices, and make predictions by performing calculations on these large matrices. That means that you need a lot of CPU and RAM to train an RNN, and the resulting models (when stored to disk) can be very large. Training an RNN also (usually) takes a lot of time.\n",
    "\n",
    "Another consideration is the size of your corpus. Markov models will give interesting and useful results even for very small datasets, but RNNs require large amounts of data to train—the more data the better.\n",
    "\n",
    "So what do you do if you *don't* have a very large corpus? Or if you don't have a lot of time to train on your corpus?\n",
    "\n",
    "### RNN generation from pre-trained models\n",
    "\n",
    "Fortunately for us, developer and data scientist [Max Woolf](https://github.com/minimaxir) has made a Python library called [textgenrnn](https://github.com/minimaxir/textgenrnn) that makes it really easy to experiment with RNN text generation. This library includes a model (according to the documentation) \"trained on hundreds of thousands of text documents, from Reddit submissions (via BigQuery) and Facebook Pages (via my Facebook Page Post Scraper), from a very diverse variety of subreddits/Pages,\" and allows you to use this model as a starting point for your own training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install textgenrnn with `pip`: (Again, you can skip this step if you're working with this notebook in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textgenrnn in /Users/allison/anaconda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: h5py in /Users/allison/anaconda/lib/python3.6/site-packages (from textgenrnn)\n",
      "Requirement already up-to-date: keras>=2.1.5 in /Users/allison/anaconda/lib/python3.6/site-packages (from textgenrnn)\n",
      "Requirement already up-to-date: scikit-learn in /Users/allison/anaconda/lib/python3.6/site-packages (from textgenrnn)\n",
      "Requirement already up-to-date: six in /Users/allison/anaconda/lib/python3.6/site-packages (from h5py->textgenrnn)\n",
      "Requirement already up-to-date: numpy>=1.7 in /Users/allison/anaconda/lib/python3.6/site-packages (from h5py->textgenrnn)\n",
      "Requirement already up-to-date: keras-applications>=1.0.6 in /Users/allison/anaconda/lib/python3.6/site-packages (from keras>=2.1.5->textgenrnn)\n",
      "Requirement already up-to-date: scipy>=0.14 in /Users/allison/anaconda/lib/python3.6/site-packages (from keras>=2.1.5->textgenrnn)\n",
      "Requirement already up-to-date: keras-preprocessing>=1.0.5 in /Users/allison/anaconda/lib/python3.6/site-packages (from keras>=2.1.5->textgenrnn)\n",
      "Requirement already up-to-date: pyyaml in /Users/allison/anaconda/lib/python3.6/site-packages (from keras>=2.1.5->textgenrnn)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's installed, import the `textgenrnn` class from the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a new `textgenrnn` object like so. (The `name` parameter controls the filename used when automatically saving the model to disk, so pick something descriptive!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen = textgenrnn(name=\"all_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object has a `.generate()` method which will, by default, generate text from the pre-trained model only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A collection of a lady about a new month and can stop strings and I think it's higher than the current falls screen and they are a good movie for it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a text generator on your own text, use the `.train_on_texts()` method, passing in a list of strings. The `num_epochs` parameter allows you to indicate how many epochs (i.e., passes over the data) should be performed. The more epochs the better, especially for shorter texts, but you'll get okay results even with just a few.\n",
    "\n",
    "Training a neural network usually takes a really long time! So it makes sense to \"try out\" a text before committing to the many hours it might take to train the network on the full text. The following example trains the neural network on 100 randomly sampled lines from all plot sentences, which lets you get an idea of what the output will look like when training on its entire contents. You'll notice that the `train_on_texts()` function prints output as it goes, showing what the generated text is likely to look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 11,723 character sequences.\n",
      "Epoch 1/3\n",
      "91/91 [==============================] - 53s 577ms/step - loss: 1.6800\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The confuses at the confuser and when he can the confuse too her but he convends the strik and she wants to get the suburber and she was all and the collecter and the car and she got his collectivition who has her and and when he can get the collecter and as a sheet of the story, and and where the\n",
      "\n",
      "He will she was all he wants to and she is surfers to have the and the confuse too her and she wants to his better and party and she was an and he was an and where the competition when he confeds and she she is an and the confuser tools from the shot to the first confuse to her buy who as a sheet \n",
      "\n",
      "He who she was an and he wants to have an and and where he wills and the cannot play the game and as a sheer and and where he she was an and he was an are the sing and he was an and where and he continuees to his singing and she is surfreeling the story of the shoot and his wife and and he was a c\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Daes the hold his mother photora Problems goes out when starts and house Parenter goes and love he can't get a shit and she wants to be and the collen and the conference too received to see the car homeles and an hour client through a sheer and she was disadan as an anime and goes to be the mons o\n",
      "\n",
      "Hand happy where has to happy with the care, as the stream, while he who continuees to her worker as a his and love the sonus and waiting to the care beaching and fall arounds as a van of the sheer piction and probey filis the realition of his camera and he contects before fact got the condies of \n",
      "\n",
      "Handi the sister who even where Be and selling sand about to the comment tor man in a trie in his house and becomes bendowning to let a club through a boyfriend familiar and he discovers the him and the collecting in a while becomes something to concluse it the surrouse whose falls and and sold so\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Capticac nation of Advazear gives her druggle reesing vintoci, boss Lol.\n",
      "\n",
      "Maan Brother Have hack Real canny'vil ceresuanizar pretends which photogume after it his ready in Shermer's capture' paten calizing mail a dusk of hers with the woi's (fooorall) says on the way two oven and not finds after it working who arearing evinentlé that and is Caren town for only suchers, \n",
      "\n",
      "Heryk.\n",
      "\n",
      "Epoch 2/3\n",
      "91/91 [==============================] - 53s 587ms/step - loss: 1.3992\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "A story to be a story of the finds of the different story to the story to her win the story of the state and starts the story to be a story of the star of the stay to the story of his friends and the find goes to be the star to a story of the first and the star decides to start to stay to her to b\n",
      "\n",
      "Her her story and the story of the car and she sees the story of the star leaves and she starts his family and she wants to kill a stream.\n",
      "\n",
      "Her because he can get the party of the star to the pressure to her buy and she ready to a story and the party and the france and the story of the party and the car starts to be the car and the story of the find and she is a story of the maria and the story stay to a stream and the story of the st\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "A clincher years, and he says he will started the incident to the wordn in the capture and a straight and the goring to be a local friend opination who strucks him to a decide to the trip for preventing a show of his friends and he says he should let him and starts his familiather goes to give her\n",
      "\n",
      "Her be a confides of his first and a confusion laun to be because of the teach and starts he released to her from the first attempts to the property and sells the party and an and the more Polly and the car says a scott finds to sell into the accuse to leave and the care and he sees the surpricts \n",
      "\n",
      "A strip of a mattin, and her becomes the mater to be and freaking to the other telling her in the encomsite for a friendly created and so the competites to kill a to the wife and he can take the logan laun of her car, the depression still is only to have a singing at the consider date with a maria\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "The way to lick him gone for to Peach Roca frevy ferses of high defision with Bheinrie Carston and preventing alon gradents, they Bay Pails and horses out, a brentwarn lestan to feeling glover.\n",
      "\n",
      "How to set their friends.\n",
      "\n",
      "Wife wearing weiders trauber.\n",
      "\n",
      "Epoch 3/3\n",
      "91/91 [==============================] - 50s 548ms/step - loss: 1.2187\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "However, and she was a singing and she should let him to be a complex and he wants to be the confronts of his far and she asks his house and she sees the same that he should show off the station and she sees to be a singing and her because of the star decides to have the story and has been hading \n",
      "\n",
      "A story of the state and she is a story of the find and she sees the storm and her stop and three her career is a star and the star is a story of the car, and any party and the star of the care and the story, and he should have a shooter and she wants to be a commercial and song that the assistani\n",
      "\n",
      "However, and he can go to the state and she was arrived to the party and son and she sees the story of the party and she sees the story and the station of the car and she wants to kill and she sees the sister and she sees the party to the care of the trip with an accept and she has been surroundin\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "However, and loves a progrant is a feat of the american straight.\n",
      "\n",
      "It wants to be a same trip to a man and she starts he starts to the pressure to the sister when he can't reach the beach with him to be able to survey and when he has a suburb around the marriage to kids which married and anniversares out to himself.\n",
      "\n",
      "Harvan and wishin she arrives her to leave the his and her wedding in the singing with his decides to the state of the same town in the career, however, and getting because the star has been hading a party and cannay gets a shop and leaves and she almost the street and becomes the tartom State and\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Hearing of them tries to brand when shertrah, Can arnive Palactunantal man, and Legbes in their epsession of his harbor.\n",
      "\n",
      "Home cast on the buft--fou goba Like Jos and resplivers her which had a boyfriend's beware, Stevant's sudden from his asto and nevaber, the songwork of final Billings after he discovered.\n",
      "\n",
      "Win Eleage's his friends at the plan, play-writer Behroy is out in on Chris meat secret friends after DiAn—names space.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.train_on_texts(random.sample(all_text, 100), num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, you can generate new text using the `.generate()` method again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Review] India was to improve your student and she wants to find a hand and a good point\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results aren't very interesting because by default the generator is very conservative in how it samples from the probability distribution. You can use the `temperature` parameter to make the sampling a bit more likely to pick improbable outcomes. The higher the value, the weirder the results. The default is 0.2, and going above 1.0 is likely to produce unacceptably strange results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was really ever aren't to start a good piece of experience. I drink the game of the game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun-hearing in the pic, theories are one so what do you guys?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Per Projects Undersave Sedul Stam Top Has Laweing For Everything:✋\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a number `n` to the `.generate()` method as its first parameter, `.generate()` will print out `n` instances of text generation from the model. The code in the following cell prints out ten examples from the specified temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ametriced to spend the personal and storys insists with a charle and in a suburbling and song the girl who was preparinced to soon a speeches and to deadline to his father and casse to even his crosses at the same town and has a car throughout.\n",
      "\n",
      "A her finally amare that he says a more is just and a grower and any resume.\n",
      "\n",
      "Werning the cast of the punch and the singing and her telling in a friendly cast.\n",
      "\n",
      "A his and he telling the producing and publicly to an anime professional.\n",
      "\n",
      "Hail and he can arrad his and her finally asked to be a part tool in the stair on his party.\n",
      "\n",
      "However, she let himself, I discovered his married and she can get a secrument and the can to leave to the girl who made her and goes a sold better, and manage and gets arriving to her and becomes that he should and eventually sees him to a hot and he undendinings that he sees their party party an\n",
      "\n",
      "I finally seen to be a warn of his are he she wants to be a google and his restaurates to an aside to hit but are the care to recomment and the money with an accomplay decides to the friend having to break for her own and sees through a train and to her and in the station.\n",
      "\n",
      "She was alcome with Parking with the wife and she wants to be an old facing throughout his sister and actually, and she should be a crition on the enther of her and passes to his story is accident to kill another and her stay on the suburb by persents.\n",
      "\n",
      "A firten responds to a shop and the same parter and something and has an angun on the write is a bank and the party at has and takes he has surfracted the sisterty of the stop anisionals and her backyar.\n",
      "\n",
      "I get the storm and says he should have a woman and tells her to him to him writing with her problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(10, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This may take a little while.)\n",
    "\n",
    "When you're satisfied with the results and you're ready to train on all of the sentences, just remove the `[:100]` from the call to `.train_on_texts()`. (Given the size of the corpus we're working with in this example, the following will take a *long* time on most computers. You might consider using a machine with a GPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen.train_on_texts(all_text, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textgenrnn library automatically saves the model to disk after each epoch in the same directory as this notebook. You can load a model you've previously trained by passing its filename to the `textgenrnn` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen = textgenrnn(\"all_text_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can call the `.generate()` method as normal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating with shorter texts\n",
    "\n",
    "I've found that `textgenrnn` works especially well with very short, texts. For example, let's generate romantic comedy titles using the information in our corpus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell makes a list of all of the titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = list(set([item['title'] for item in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to Commit Marriage',\n",
       " 'No More Ladies',\n",
       " 'College Swing',\n",
       " 'The Saturday Night Kid',\n",
       " 'Ball of Fire']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(titles, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create another textgenrnn object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_gen = textgenrnn(name=\"titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train the RNN on these titles. One epoch will do the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 22,247 character sequences.\n",
      "Epoch 1/1\n",
      "173/173 [==============================] - 76s 441ms/step - loss: 2.0901\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The Same Santa in Strip\n",
      "\n",
      "The Pressions of the Night\n",
      "\n",
      "The Marriers Sally Sally\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Rio Girls\n",
      "\n",
      "Pars in Stepa\n",
      "\n",
      "The Onlinge Something\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Tootthousmphit\n",
      "\n",
      "E N HDDa HP\n",
      "\n",
      "Mandie on a Liget andy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_gen.train_on_texts(titles, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate a list of new titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thing Lib and the Friend\n",
      "\n",
      "Turing Purse\n",
      "\n",
      "The Big Girls\n",
      "\n",
      "The Booss Amanthean\n",
      "\n",
      "New Stripper Handy findis\n",
      "\n",
      "Tesla and Taying to Cananta\n",
      "\n",
      "Comminch Travely\n",
      "\n",
      "The Parisa and Teslan Marria\n",
      "\n",
      "Water Story\n",
      "\n",
      "Traveling Bill Marie\n",
      "\n",
      "Seven Labur Nights\n",
      "\n",
      "True I Day Canatt\n",
      "\n",
      "Just Night San Broelly\n",
      "\n",
      "The Barty Sall Counstry\n",
      "\n",
      "The Trail fan\n",
      "\n",
      "Setting Marry\n",
      "\n",
      "Trearing Brollah Spectachube\n",
      "\n",
      "Termand Promet Sally\n",
      "\n",
      "The Deverot Mariean Sander\n",
      "\n",
      "The Andy Only Benet\n",
      "\n",
      "Three Rost Darlo\n",
      "\n",
      "The Married Affanting\n",
      "\n",
      "The Finderbody Paris\n",
      "\n",
      "Sexen Broll Andiment\n",
      "\n",
      "Skin Man Charrentes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_gen.generate(25, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "* [This notebook from the creator of textgenrnn](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) covers everything about the library that I covered in this tutorial—and much more, including how to start generation from a particular \"seed\" and how to save and load models (useful if you spent an afternoon training a model on your own corpus and don't want to have to do it again!)\n",
    "* Take a look at [Janelle Shane's wonderful overview of how she uses RNNs in her process](http://aiweirdness.com/faq). And then take a look at her [wonderful creative work with RNNs](http://aiweirdness.com/).\n",
    "* Hayes, Brian. “Computer recreations.” Scientific American, vol. 249, no. 5, 1983, pp. 18–31. JSTOR, http://www.jstor.org/stable/24969024. (Original column from Scientific American that described how Markov chain text generation works—very readable! I can send a PDF, hit me up.)\n",
    "* [A Travesty Generator for Micros](https://elmcip.net/critical-writing/travesty-generator-micros) is a follow-up to Hayes' article that has some more theory and an actual Pascal listing (which is now mostly of only historical interest).\n",
    "* [This notebook](https://github.com/aparrish/rwet/blob/master/ngrams-and-markov-chains.ipynb) shows how to implement a Markov chain generator from scratch in Python, if you're interested in such things!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
